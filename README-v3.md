
# ğŸ§ª CIEO Codificador v3 (TAU + BioBERT Edition)

Este sistema permite sugerir cÃ³digos de clasificaciÃ³n clÃ­nica (inicialmente CIE-O 3.2) desde texto libre, utilizando modelos de lenguaje como BioBERT y una base terminolÃ³gica unificada (TAU) que incluye SNOMED CT y CIE-11.

## ğŸš€ CÃ³mo levantar el sistema

### 1. Base de datos
Levanta PostgreSQL con Docker:
```bash
docker-compose up postgres
```
Ejecuta el script SQL:
```bash
psql -U cieo_user -d cieo_db -f db-schema-v3.sql
```
Carga datos base si lo deseas:
```bash
psql -U cieo_user -d cieo_db -c "\copy terminologias FROM 'tau_base.csv' CSV HEADER;"
```

### 2. Backend (FastAPI + Transformers)
```bash
cd backend-v3
pip install -r requirements.txt
uvicorn app.main:app --reload
```

### 3. Frontend (React)
```bash
cd frontend-v3
npm install
npm run dev
```

## ğŸ“ Endpoints disponibles

- `POST /sugerir-codigo`: recibe texto, retorna sugerencia de cÃ³digo desde TAU.
- `GET /`: mensaje de prueba.

## ğŸ“Š Base de datos

- `terminologias`: tabla principal con cÃ³digos, traducciones y sinÃ³nimos.
- `relaciones_equivalentes`: equivalencias entre cÃ³digos (CIE-O, SNOMED, CIE-11).

## ğŸ§  Arquitectura IA (actual)
1. **BioBERT embeddings**.
2. **ComparaciÃ³n con TAU** (por similitud).
3. **Sugerencia del cÃ³digo mÃ¡s probable**.
4. **Registro de correcciones para fine-tuning**.

## ğŸ“Œ Roadmap personal como desarrollador clÃ­nico-IA

| Etapa | Objetivo |
|-------|----------|
| âœ… MVP 1 | Codificador CIE-O con BioBERT + TAU |
| ğŸ”œ MVP 2 | Integrar SNOMED + equivalencias |
| ğŸ”œ MVP 3 | Carga progresiva de traducciones |
| ğŸ”œ MVP 4 | Dataset de entrenamiento incremental |
| ğŸ”œ MVP 5 | Fine-tuning supervisado propio |
| ğŸ”œ MVP 6 | Agente clÃ­nico interactivo con bÃºsqueda semÃ¡ntica |

Tu objetivo no es solo codificar diagnÃ³sticos, sino entrenar un sistema que **aprenda contigo**, mejore con cada revisiÃ³n, y sea capaz de ayudarte a razonar clÃ­nicamente.

ğŸ§  Objetivo: Construir la mejor IA gratuita para codificaciÃ³n mÃ©dica, con base en CIE-O, SNOMED y documentos clÃ­nicos.
ğŸ”© 1. Modelo base (IA generativa / comprensiva)
Componente	Rol	Modelo recomendado	Â¿Por quÃ©?
ğŸ§  LLM principal	Entender PDFs, responder preguntas, asistir diagnÃ³stico	Mistral o Phi-2	Gratuitos, eficientes y potentes
ğŸ” Indexador documental	Convertir PDFs en conocimiento consultable	LlamaIndex o Haystack	Ideal para RAG con libros/manuales
ğŸ“š Embeddings	BÃºsqueda semÃ¡ntica	InstructorEmbedding o GTE-base	Gratuitos y multiuso

ğŸ“Š 2. Codificador mÃ©dico (semÃ¡ntico y estructurado)
Componente	Rol	Modelo recomendado	Â¿Por quÃ©?
ğŸ§¬ Codificador clÃ­nico	Embedding de tÃ©rminos mÃ©dicos	BioBERT	Optimizado para lenguaje biomÃ©dico
ğŸ§® Comparador semÃ¡ntico	Buscar el cÃ³digo mÃ¡s cercano	Distancia coseno con FAISS	Ultra rÃ¡pido y gratuito
ğŸ§° Sistema de entrenamiento	Fine-tuning del modelo	PyTorch + HuggingFace	Gratuito y bien documentado

ğŸ’¾ 3. Base de datos mÃ©dica curada (TAU)
Ya lo tienes con:

terminologias (estructura comÃºn)

relaciones_equivalentes (cruces SNOMED/CIE-11)

Posibilidad de importar de Excel/PDF/API

ğŸ–¥ï¸ 4. Requisitos de hardware
Nivel	RAM	GPU recomendada	Â¿Permite quÃ©?
BÃ¡sico	16 GB	Ninguna	Ingesta + embeddings + consultas
Medio	32 GB	RTX 3060-3070	LLM de 7B en CPU o GPU lenta
Avanzado	64 GB	RTX 4090 o A6000	Entrenar modelos, codificador + generativo en paralelo

ğŸ”„ 5. InteracciÃ³n y entrenamiento
PodrÃ¡s:

Entrenar desde texto libre.

Agregar nuevas fuentes (PDFs, libros, artÃ­culos).

Crear sinÃ³nimos, traducciones y equivalencias.

Rastrear quiÃ©n entrenÃ³ quÃ© (auditorÃ­a mÃ©dica).

Conectarlo luego a tu sistema LIS de APA.

---

ğŸ§  Resumen del avance - Entrenamiento e IndexaciÃ³n IA CIE-O
ğŸ“ Estructura de Proyecto Establecida
java
Copiar
Editar
TAU_APA/
â”œâ”€â”€ backend-v3/
â”‚   â”œâ”€â”€ data/                        â† Documentos fuente como CIE-O 3.1 PDF
â”‚   â”œâ”€â”€ index_store/cieo/           â† Ãndice persistente de vectores (vector DB)
â”‚   â”œâ”€â”€ indexadores/
â”‚   â”‚   â””â”€â”€ indexar_pdf_cieo.py     â† Script de indexaciÃ³n inteligente con LLM
â”‚   â”œâ”€â”€ Consultar Rag Cieo.py       â† Script de consulta interactiva (RAG)
âœ… Objetivo de hoy
Construir una IA capaz de comprender y razonar sobre el manual CIE-O 3.1 en espaÃ±ol, para utilizarlo como base de conocimiento mÃ©dico en codificaciÃ³n oncolÃ³gica.

âš™ï¸ Pipeline completado
ğŸ“š Ingesta e IndexaciÃ³n de CIE-O PDF

Cargamos el manual como SimpleDirectoryReader

Lo dividimos en fragmentos con SentenceSplitter

Creamos embeddings con all-MiniLM-L6-v2

Integramos un LLM local (Mistral-7B-Instruct-v0.3)

Se guardÃ³ el Ã­ndice vectorial en index_store/cieo

ğŸ¤– Consulta basada en recuperaciÃ³n (RAG)

Se configurÃ³ un RetrieverQueryEngine conectado al Ã­ndice

Permite consultar conceptos desde terminal con respuestas contextuales generadas por el LLM

ğŸ” AutenticaciÃ³n Hugging Face

Se solucionaron problemas de token y autenticaciÃ³n

El modelo Mistral fue correctamente accedido con login persistente

ğŸ’¡ Ideas clave del diseÃ±o
El Ã­ndice vectorial serÃ¡ usado por un agente mÃ¡s complejo en etapas futuras

El modelo debe sugerir cÃ³digos, explicar decisiones y aprender de correcciones

El entrenamiento se basa en ingestiÃ³n progresiva de documentos normativos (CIE-O, CAP, SNOMED, etc.)

Se prevÃ© una interfaz web y conexiÃ³n con el frontend en React

ğŸ› ï¸ PrÃ³ximos pasos sugeridos
ğŸ§ª Verificar la calidad de los chunks indexados (contenido, longitud, metadatos)

ğŸ§  Entrenar al modelo con consultas clave para testear razonamiento

ğŸ“„ Agregar mÃ¡s documentos (p. ej., tablas SNOMED, CIE-11)

ğŸ”„ Interfaz de consulta desde frontend (formulario, respuestas enriquecidas)

ğŸ§¬ Futuro: codificador contextual que lea el diagnÃ³stico completo y determine cÃ³digo morfolÃ³gico + topogrÃ¡fico.

---

ğŸ§  PIPELINE MAESTRO DE INDEXACIÃ“N Y RAZONAMIENTO â€“ CIE-O
ğŸ¯ Objetivo General
Construir un sistema de IA local que permita sugerir, validar y razonar codificaciones mÃ©dicas (inicialmente CIE-O 3.1) desde texto libre, con generaciÃ³n explicativa, trazabilidad de fuentes y entrenamiento continuo desde el frontend.

ğŸ§± 1. IndexaciÃ³n SemÃ¡ntica + Generativa
Script principal: indexar_pdf_cieo.py

Fuente: CIEO-3.1._ACCESIBLE.pdf (manual en espaÃ±ol)

Procesos:

Carga del PDF y fragmentaciÃ³n inteligente con SentenceSplitter

VectorizaciÃ³n semÃ¡ntica con all-MiniLM-L6-v2

Carga de modelo generativo Mistral-7B-Instruct-v0.3 para razonamiento explicativo

Almacenamiento en ./index_store/cieo con persistencia en disco

âœ… Indexa 700 fragmentos del manual con chunking consistente

ğŸ§ª 2. Motor de Consulta RAG (Retrieval-Augmented Generation)
Script: consultar_rag_cieo.py

MÃ³dulo: RetrieverQueryEngine de LlamaIndex

Entrada: Preguntas en lenguaje natural desde terminal

Salida: Texto generado por el LLM, usando los fragmentos indexados como respaldo.

Soporte a futuro:

AÃ±adir referencias visibles al fragmento fuente (para validaciÃ³n clÃ­nica)

AÃ±adir modo rÃ¡pido vs explicativo (para performance clÃ­nica vs docencia)

ğŸ”„ 3. NormalizaciÃ³n y ExpansiÃ³n TerminolÃ³gica
Base: terminologias (TAU)

Fuentes previstas:

Excel de morfologÃ­a v26

SNOMED CT (por API o dumps)

CIE-11

Flujo esperado:

Scripts de carga flexibles por formato (ingestores/)

Reconocimiento automÃ¡tico de columnas

CuraciÃ³n automÃ¡tica + revisiÃ³n humana

Modo sugerencia con IA desde texto libre + embeddings

ğŸ¤– 4. Futuro Agente DiagnÃ³stico (Copiloto MÃ©dico)
Lectura completa del informe

DetecciÃ³n de entidades: lateralidad, grado, topografÃ­a

InteracciÃ³n tipo chat con explicaciÃ³n y sugerencia de codificaciÃ³n

Posibilidad de autocompletar sinÃ³nimos, correcciones ortogrÃ¡ficas y terminologÃ­as vinculadas

Flujo de entrenamiento activo desde la UI (aceptar/sugerir/editar cÃ³digo = feedback al modelo)

ğŸŒ 5. Interfaz Web (frontend)
Webapp en React (futura etapa)

Entrada del texto libre de diagnÃ³stico

Sugerencias de cÃ³digo automÃ¡ticas con botones de:

ğŸ” "Buscar en manual"

ğŸ§  "Razonar con IA"

ğŸ”„ "Consultar SNOMED" / "Consultar CIE-11"

ValidaciÃ³n cruzada de respuestas (p. ej. comparar CIE-O vs SNOMED)

ğŸ“Œ 6. Trazabilidad, Fine-tuning y Memoria
Cada sugerencia aceptada:

Se registra para refinar embeddings

Actualiza sinÃ³nimos, definiciones o nuevas relaciones

Opcional: puede nutrir el entrenamiento de un modelo propio

Todos los cambios deben trazarse por usuario, tiempo y origen

ğŸ”§ Requerimientos tÃ©cnicos actuales
âœ… Funciona localmente en:

ASUS Zephyrus G16

Intel Core Ultra i9

32 GB RAM

GPU RTX 4070

âš ï¸ Consideraciones para escalar
Requisito	Estado Actual	RecomendaciÃ³n para IA RÃ¡pida
RAM	32 GB	Suficiente para modelos 7B
GPU VRAM	8 GB+	Ideal: 24 GB para tuning / 16 GB para inferencia
Disco SSD	1 TB NVMe	OK
CPU	Intel Ultra i9	OK, pero el cuello de botella serÃ¡ la GPU
Sistema dedicado (headless)	âŒ	ğŸ¤” Considerar torre con refrigeraciÃ³n activa